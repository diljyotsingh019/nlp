{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS-NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9KkNTZegWcr",
        "colab_type": "text"
      },
      "source": [
        "# Part of Speech Tagging\n",
        "\n",
        "Part of Speech (POS) Tagging  a sentence in a broader sense refers to the addition of labels of the verb, noun,etc.by the context of the sentence. Generic tagging of POS is manually not possible as some words may have different (ambiguous) meanings according to the structure of the sentence. \n",
        "\n",
        "Conversion of text in the form of list of words is done first. Afterwords the list is traversed and a tag is assigned to individual word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-poRRDleXrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install NLTK if not already installed...uncomment the next cell and run it.\n",
        "#! pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMPz1FMrfFXA",
        "colab_type": "code",
        "outputId": "8f53c01c-b304-42d9-c55b-638842adc91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f9TIJ39fk3K",
        "colab_type": "code",
        "outputId": "2dcad511-f573-440a-cea7-a6ae564a89af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd8bUXqR1t2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f8494faa-e0ec-45ca-c246-9c6d562fc1aa"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJ7cS4D1-vc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "11bdd613-7e8d-47e8-bf28-232f76edf799"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXGKBmLPf7fL",
        "colab_type": "text"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5S3IGmQfp5p",
        "colab_type": "code",
        "outputId": "d12d3846-e61c-4f4e-f182-4020d7b75cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "text=\"A quick brown fox jumps over the lazy dogs.\"\n",
        "\n",
        "tokens_tag = nltk.pos_tag(text)\n",
        "\n",
        "print(\"After Token:\",tokens_tag)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After Token: [('A', 'DT'), (' ', 'JJ'), ('q', 'NN'), ('u', 'NN'), ('i', 'NN'), ('c', 'VBP'), ('k', 'NN'), (' ', 'NNP'), ('b', 'NN'), ('r', 'NN'), ('o', 'NN'), ('w', 'NN'), ('n', 'JJ'), (' ', 'NNP'), ('f', 'NN'), ('o', 'NN'), ('x', 'NNP'), (' ', 'NNP'), ('j', 'NN'), ('u', 'JJ'), ('m', 'NN'), ('p', 'NN'), ('s', 'NN'), (' ', 'NNP'), ('o', 'VBZ'), ('v', 'FW'), ('e', 'FW'), ('r', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('h', 'NN'), ('e', 'NN'), (' ', 'NNP'), ('l', 'VBZ'), ('a', 'DT'), ('z', 'NN'), ('y', 'NN'), (' ', 'NNP'), ('d', 'NN'), ('o', 'NN'), ('g', 'NN'), ('s', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9u8tf-hSLe",
        "colab_type": "code",
        "outputId": "5714f847-d6f2-4a81-87bd-900b5f706ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"everybody should learn machine learning with python\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['everybody', 'should', 'learn', 'machine', 'learning', 'with', 'python']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjZfP8gYIztJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85859424-29a3-43bd-975b-6613863f4132"
      },
      "source": [
        "tag = nltk.pos_tag(tokens)\n",
        "print(tag)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('everybody', 'NN'), ('should', 'MD'), ('learn', 'VB'), ('machine', 'NN'), ('learning', 'VBG'), ('with', 'IN'), ('python', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbEKDV-cSzLS",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition (NER)\n",
        "\n",
        "Named entity recognition (NER) is probably the first step towards information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. NER is used in many fields in Natural Language Processing (NLP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcB99OStSwug",
        "colab_type": "text"
      },
      "source": [
        "## Chunking\n",
        "\n",
        "We need to implement noun phrase chunking to identify named entities using a regular expression consisting of rules that indicate how sentences should be chunked.\n",
        "\n",
        "In this case the chunk pattern consists of one rule - a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwVoTB2wPaPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "6781fb86-e52b-4aea-82f5-3e4ddde0e456"
      },
      "source": [
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp  =nltk.RegexpParser(grammar)\n",
        "\n",
        "\n",
        "\n",
        "text = \"Jack and Jill went up the hill, to fetch a pale of water.\"\n",
        "\n",
        "# Tokenize words\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "# POS tag the words\n",
        "tag = nltk.pos_tag(tokens)\n",
        "print(tag)\n",
        "\n",
        "# Chunking\n",
        "result = cp.parse(tag)\n",
        "print(result)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Jack', 'and', 'Jill', 'went', 'up', 'the', 'hill', ',', 'to', 'fetch', 'a', 'pale', 'of', 'water', '.']\n",
            "[('Jack', 'NNP'), ('and', 'CC'), ('Jill', 'NNP'), ('went', 'VBD'), ('up', 'RP'), ('the', 'DT'), ('hill', 'NN'), (',', ','), ('to', 'TO'), ('fetch', 'VB'), ('a', 'DT'), ('pale', 'NN'), ('of', 'IN'), ('water', 'NN'), ('.', '.')]\n",
            "(S\n",
            "  Jack/NNP\n",
            "  and/CC\n",
            "  Jill/NNP\n",
            "  went/VBD\n",
            "  up/RP\n",
            "  (NP the/DT hill/NN)\n",
            "  ,/,\n",
            "  to/TO\n",
            "  fetch/VB\n",
            "  (NP a/DT pale/NN)\n",
            "  of/IN\n",
            "  (NP water/NN)\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhV_t23FLUAP",
        "colab_type": "text"
      },
      "source": [
        "### Another Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYcbgmVcS3V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"\"\"Alice and Bob went to America to see the President at Washington D.C\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtiZ65FvoASh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c828c156-0284-45c0-f830-cbeeaed65170"
      },
      "source": [
        "tokens = nltk.word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Alice', 'and', 'Bob', 'went', 'to', 'America', 'to', 'see', 'the', 'President', 'at', 'Washington', 'D.C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTo5uIEtoCvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4db80977-12f6-481f-96ef-08d0e632b29d"
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Alice', 'NNP'), ('and', 'CC'), ('Bob', 'NNP'), ('went', 'VBD'), ('to', 'TO'), ('America', 'NNP'), ('to', 'TO'), ('see', 'VB'), ('the', 'DT'), ('President', 'NNP'), ('at', 'IN'), ('Washington', 'NNP'), ('D.C', 'NNP')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nw7JoM51RXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "da6bf378-763e-441d-d26f-982d4d943b1f"
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Alice', 'NNP'), ('and', 'CC'), ('Bob', 'NNP'), ('went', 'VBD'), ('to', 'TO'), ('America', 'NNP'), ('to', 'TO'), ('see', 'VB'), ('the', 'DT'), ('President', 'NNP'), ('at', 'IN'), ('Washington', 'NNP'), ('D.C', 'NNP')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIH744d_oElG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3b825a08-037c-459d-e772-29654f0ec128"
      },
      "source": [
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "print(entities)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  Alice/NNP\n",
            "  and/CC\n",
            "  (PERSON Bob/NNP)\n",
            "  went/VBD\n",
            "  to/TO\n",
            "  (GPE America/NNP)\n",
            "  to/TO\n",
            "  see/VB\n",
            "  the/DT\n",
            "  President/NNP\n",
            "  at/IN\n",
            "  (ORGANIZATION Washington/NNP)\n",
            "  D.C/NNP)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emAPB0ua1ZA_",
        "colab_type": "text"
      },
      "source": [
        "### Another Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty43rRHU1Cwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIWi7v3h1M3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "82ff71f9-0598-4114-b66d-5e37376671ec"
      },
      "source": [
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['European', 'authorities', 'fined', 'Google', 'a', 'record', '$', '5.1', 'billion', 'on', 'Wednesday', 'for', 'abusing', 'its', 'power', 'in', 'the', 'mobile', 'phone', 'market', 'and', 'ordered', 'the', 'company', 'to', 'alter', 'its', 'practices']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOp1km3z1SiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6cb4aaa7-9768-417d-8f89-5f369968955a"
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('European', 'JJ'), ('authorities', 'NNS'), ('fined', 'VBD'), ('Google', 'NNP'), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('market', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('the', 'DT'), ('company', 'NN'), ('to', 'TO'), ('alter', 'VB'), ('its', 'PRP$'), ('practices', 'NNS')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU_WTA_I1VlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "f938f3be-0b32-4d09-d019-742569cc9ca2"
      },
      "source": [
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "print(entities)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (GPE European/JJ)\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  (PERSON Google/NNP)\n",
            "  a/DT\n",
            "  record/NN\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  power/NN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  mobile/JJ\n",
            "  phone/NN\n",
            "  market/NN\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  the/DT\n",
            "  company/NN\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}